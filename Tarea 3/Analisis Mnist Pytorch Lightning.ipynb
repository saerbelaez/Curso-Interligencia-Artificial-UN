{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Analisis Mnist Pytorch Lightning.ipynb","provenance":[{"file_id":"1rVrityAhY8YsFrWl9P8bIfFSWAByj4-a","timestamp":1654814301671}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["#Análisis Fashion MNIST usando Pytorch Lightning\n","\n","En este cuaderno se transcribe el código propuesto para una red neuronal que permita clasificar prendas de vestir empleando la base de datos Fashion Mnist. Para el análisis se va a usar Pytorch Lightning"],"metadata":{"id":"rKUdQ6mKnyZi"}},{"cell_type":"code","source":["!pip install pytorch_lightning\n","import pytorch_lightning as pl\n","from pytorch_lightning import LightningModule\n","from torch.autograd import Variable\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","from torchmetrics import Accuracy\n","from datetime import datetime\n","from torch.nn.functional import softmax"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IreAEOMhoJlv","executionInfo":{"status":"ok","timestamp":1654817960012,"user_tz":300,"elapsed":9164,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}},"outputId":"3f4ac44a-1229-4bdc-a281-a1f37dad21cd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (1.6.4)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n","Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.9.1)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.0)\n","Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.2.0)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n","Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.17.3)\n","Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.2)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->pytorch_lightning) (1.15.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.46.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.7)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.5.18.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.7.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n"]}]},{"cell_type":"markdown","source":["Para la especificación del modelo se usa el modulo de lightning y se define la red neuronal que se va a ajustar."],"metadata":{"id":"b6DaVqtHyo3W"}},{"cell_type":"code","source":["class NeuralNetwork(pl.LightningModule):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","            nn.ReLU()\n","        )\n","        \n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork()\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qS4Ur99VsK2X","executionInfo":{"status":"ok","timestamp":1654817960014,"user_tz":300,"elapsed":10,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}},"outputId":"f8775f09-25a4-4006-834f-86ff9fa6e595"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","    (5): ReLU()\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["A continuación se define una para ejecutar el proceso de entrenamiento"],"metadata":{"id":"6u4MoZQQyxcE"}},{"cell_type":"code","source":["class Trainer:\n","    def __init__(self, model, loss_fn, optimizer, metrics=None,\n","                 metric_names=None,\n","                 writer=None, path_to_save='',\n","                 learning_rate = 1e-3,\n","                 batch_size = 64,\n","                 epochs = 5, n_report= 1000):\n","        self.model = model\n","        self.loss_fn = loss_fn\n","        self.optimizer = optimizer\n","        self.metrics_train = metrics\n","        self.metrics_valid = self.metrics_train.copy()\n","        self.metric_names = metric_names\n","\n","        self.writer = writer\n","        \n","        self.learning_rate = learning_rate\n","        self.batch_size = batch_size\n","        self.epochs = epochs\n","        self.n_report = n_report\n","        \n","        self.path_to_save = path_to_save\n","\n","        self.best_model = None\n","        \n","        self.training_loader = None\n","\n","        self.validation_loader = None\n","     \n","    def set_model(self, model):\n","        self.model = model\n","    \n","    def set_loss(self, loss):\n","        self.loss = loss\n","        \n","    def set_optimizer(self, optimizer):\n","        self.optimizer = optimizer\n","        \n","    def set_writer(self, writer):\n","        self.writer =  writer\n","\n","    def get_model(self):\n","        return self.model\n","    \n","    \n","    def set_hiperparameters(self,\n","                 learning_rate = 1e-3,\n","                 batch_size = 64,\n","                 epochs = 5):\n","        self.learning_rate = learning_rate\n","        self.batch_size = batch_size\n","        self.epochs = epochs        \n","    \n","    def _train_one_epoch_(self, epoch_index):\n","        running_loss = 0.\n","        last_loss = 0.\n","\n","        for i, data in enumerate(self.training_loader):\n","\n","            inputs, labels = data\n","\n","            self.optimizer.zero_grad()\n","\n","            outputs = self.model(inputs)\n","            predicts = softmax(outputs, dim=-1)\n","\n","            loss = self.loss_fn(outputs, labels)\n","            loss.backward()\n","\n","            self.optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            running_metrics = self._metric_step_(predicts, labels, metric_compute=False, \n","                                          validation=False)\n","            \n","            if i % self.n_report == (self.n_report-1):\n","\n","                last_loss = running_loss / self.n_report\n","                running_loss = 0.\n","\n","                last_metrics = self._metric_step_(None, None, metric_compute=True, \n","                                          validation=False)\n","                \n","                print('Pérdida en el lote {} : {}'.format(i + 1, last_loss))\n","                \n","                print_m = ''\n","                for j in range(len(metrics)):\n","                    print_m += self.metric_names[j] + ': ' + str(last_metrics[j]) + ' '\n","                print('Métricas en el lote {} : {}'.format(i + 1, print_m))\n","                \n","                if self.writer is not None:\n","                    tb_x = epoch_index * len(training_loader) + i + 1\n","\n","                    self.writer.add_scalar('Pérdida/Entrenamiento', last_loss, tb_x)\n","\n","                    for i in range(len(last_metric)):\n","                        self.writer.add_scalar(self.metric.names[i] + '/Entrenamiento', \n","                                               last_metrics[i], tb_x)\n","                        \n","                \n","                \n","    def _validation_step_(self, validation=True):\n","\n","        if validation:\n","            data_loader = self.validation_loader\n","        else:\n","            data_loader = self.training_loader\n","        \n","        running_vloss = 0.0   \n","        for i, vdata in enumerate(data_loader):\n","            vinputs, vlabels = vdata\n","            voutputs = self.model(vinputs)\n","            vpredicts = softmax(voutputs,dim=-1)\n","            vloss = self.loss_fn(voutputs, vlabels)\n","            \n","            running_vloss += vloss\n","            _  = self._metric_step_(vpredicts, vlabels, \n","                            metric_compute=False, validation= validation)\n","\n","        avg_vloss = running_vloss / (i + 1)\n","        v_metrics =   self._metric_step_(None, None, metric_compute=True, \n","                                          validation= validation)\n","        \n","        return avg_vloss, v_metrics\n","        \n","    def _metric_step_(self, predicts, labels, metric_compute=False, validation=False):\n","\n","        if validation:\n","            metrics = self.metrics_valid\n","        else:\n","            metrics = self.metrics_train\n","        \n","        if predicts is not None and labels is not None:\n","            for i, metric in enumerate(metrics):\n","                metrics[i].update(predicts, labels)\n","        \n","        if metric_compute:\n","            values = [metric.compute().item() for metric in metrics]\n","            for metric in metrics:\n","                metric.reset() \n","        else:\n","            values = [metric(predicts, labels).item() for metric in metrics]\n","    \n","        return values\n","      \n","    \n","    def _train_loop_(self):\n","\n","        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n","        epoch_number = 0\n","\n","\n","        best_vloss = 1_000_000.\n","        \n","         \n","\n","        for epoch in range(self.epochs):\n","            print('época {}:'.format(epoch_number + 1))\n","            \n","\n","            model.train(True)\n","\n","            self._train_one_epoch_(epoch_number)\n","\n","\n","            self.model.train(False)\n","            \n","            e_loss, e_metrics = self._validation_step_(validation=False)\n","            v_loss, v_metrics = self._validation_step_(validation=True)\n","            \n","            print('Pérdida entrenamiento: {}, validación {}'.format(e_loss, v_loss))\n","            \n","            print_m_e = ''\n","            for i in range(len(e_metrics)):\n","                print_m_e += self.metric_names[i] + ': ' + str(e_metrics[i]) + ' '\n","            print_m_v = ''\n","            for i in range(len(v_metrics)):\n","                print_m_v += self.metric_names[i] + ': ' + str(v_metrics[i]) + ' '     \n","            print('Métricas en entrenamiento : {}, validación {} '.format(print_m_e, print_m_v))\n","\n","\n","            if self.writer is not None:\n","                self.writer.add_scalars('Pérdida entrenamiento v.s. Pérdida validación',\n","                                { 'Entrenamiento' : e_loss, 'Validación' : e_vloss },\n","                                epoch_number + 1)\n","                \n","                for i in range(len(e_metrics)):  \n","                    self.writer.add_scalars(self.metric.names[i] + 'entrenamiento v.s. validación',\n","                                { 'Entrenamiento' : e_metrics[i], 'Validación' : v_metrics[i] },\n","                                epoch_number + 1)\n","                  \n","                self.writer.flush()\n","\n","            if  v_loss < best_vloss:\n","                best_vloss = v_loss\n","                model_path = self.path_to_save + 'model_{}_{}'.format(timestamp, epoch_number)\n","                torch.save(model.state_dict(), model_path)\n","                self.path_best_model = model_path\n","\n","            epoch_number += 1 \n","\n","       \n","                    \n","            \n","    def fit(self, train_data, val_data, epochs=None, writer=None, best_loss=True):\n","        if writer is not None:\n","            self.writer = writer\n","        if epochs is not None:\n","            self.epochs = epochs\n","\n","        self.training_loader = train_data\n","\n","        self.validation_loader = val_data\n","        \n","\n","        self._train_loop_()\n","\n","        if best_loss:\n","            self.model.load_state_dict(torch.load(self.path_best_model))"],"metadata":{"id":"ZqNPIR15vene","executionInfo":{"status":"ok","timestamp":1654817960733,"user_tz":300,"elapsed":725,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Adicional se define una clase para generar el conjunto de entrenamiento y validación"],"metadata":{"id":"vUY0ZXJmy8z0"}},{"cell_type":"code","source":["class Data():\n","    def __init__(self, dataset=None, batch_size=64, shuffle=True):\n","        self.dataset = dataset\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self._data = DataLoader(dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n","    \n","    # getter\n","    def get_data(self):\n","        return self._data\n","    \n","    # setter\n","    def set_data(self, dataset):\n","        self._dataset = dataset\n","        self._data = DataLoader(self._dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n","    \n","    # crea la propiedad data\n","    data = property(get_data, set_data)\n","    \n","    def __len__(self):\n","        return len(self._data)\n","    "],"metadata":{"id":"mt7_Icfkud6v","executionInfo":{"status":"ok","timestamp":1654817960734,"user_tz":300,"elapsed":7,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Se generan los conjuntos de entramiento y prueba"],"metadata":{"id":"KYaCN6b8zE2l"}},{"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))])\n","\n","train_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=transform\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=transform\n",")"],"metadata":{"id":"JClX6ndxzmje","executionInfo":{"status":"ok","timestamp":1654817961013,"user_tz":300,"elapsed":284,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train = Data(train_data, batch_size=32)\n","validation = Data(test_data, batch_size=32, shuffle=False)"],"metadata":{"id":"ZUJDqf2Qt2Tn","executionInfo":{"status":"ok","timestamp":1654817961014,"user_tz":300,"elapsed":6,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Ahora se definen los optimizadores y las funciones de pérdida. Debido a que la red que se está entrenando es realtivamente compleja, se guarda el checkpoint para usarlo con otros datos."],"metadata":{"id":"pkl61Tsrzt59"}},{"cell_type":"code","source":["model = NeuralNetwork()\n","\n","# Optimizador\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","# Función de pérdida\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","# initializa métrica\n","# se espera una lista de métricas\n","metrics = [Accuracy()] # accuracy\n","# pasar nombre en español de la métrica\n","# TODO hacer esto con una clase traductora\n","metric_names = ['Exactitud']\n","# path para almacenar los pesos de los mejores modelos\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","path_to_save = '/content/gdrive/MyDrive/Colab Notebooks'\n","\n","# Trainer\n","trainer = Trainer(model=model, loss_fn=loss_fn,  \n","                  optimizer=optimizer, metrics=metrics, \n","                  metric_names = metric_names,\n","                  n_report=375, path_to_save= path_to_save )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKMhJeUtus_G","executionInfo":{"status":"ok","timestamp":1654817962369,"user_tz":300,"elapsed":1360,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}},"outputId":"90b4633a-2231-4390-a379-86a05009ad04"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Se ajusta el modelo de entramiento a los datos de validación para determinar su precisión"],"metadata":{"id":"MaqW_4RFz7L8"}},{"cell_type":"code","source":["trainer.fit(train.data, validation.data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3kQZ54FKwSV1","executionInfo":{"status":"ok","timestamp":1654818291089,"user_tz":300,"elapsed":328725,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}},"outputId":"2816a59b-8ff1-448c-c69a-9902a8bedacd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["época 1:\n","Pérdida en el lote 375 : 1.4949666884740194\n","Métricas en el lote 375 : Exactitud: 0.4857499897480011 \n","Pérdida en el lote 750 : 1.1020420747598012\n","Métricas en el lote 750 : Exactitud: 0.6317499876022339 \n","Pérdida en el lote 1125 : 0.808643186767896\n","Métricas en el lote 1125 : Exactitud: 0.746916651725769 \n","Pérdida en el lote 1500 : 0.6376968868970871\n","Métricas en el lote 1500 : Exactitud: 0.8212500214576721 \n","Pérdida en el lote 1875 : 0.6097861173550287\n","Métricas en el lote 1875 : Exactitud: 0.8303333520889282 \n","Pérdida entrenamiento: 0.5756624341011047, validación 0.6217970252037048\n","Métricas en entrenamiento : Exactitud: 0.8401833176612854 , validación Exactitud: 0.822700023651123  \n","época 2:\n","Pérdida en el lote 375 : 0.6160221873521805\n","Métricas en el lote 375 : Exactitud: 0.8335833549499512 \n","Pérdida en el lote 750 : 0.5837854881683986\n","Métricas en el lote 750 : Exactitud: 0.8454166650772095 \n","Pérdida en el lote 1125 : 0.5674816248615583\n","Métricas en el lote 1125 : Exactitud: 0.8524166941642761 \n","Pérdida en el lote 1500 : 0.5842154634793599\n","Métricas en el lote 1500 : Exactitud: 0.8472499847412109 \n","Pérdida en el lote 1875 : 0.5610184919436773\n","Métricas en el lote 1875 : Exactitud: 0.8482499718666077 \n","Pérdida entrenamiento: 0.5710232257843018, validación 0.6205582618713379\n","Métricas en entrenamiento : Exactitud: 0.8400333523750305 , validación Exactitud: 0.8224999904632568  \n","época 3:\n","Pérdida en el lote 375 : 0.5502252042889595\n","Métricas en el lote 375 : Exactitud: 0.8514166474342346 \n","Pérdida en el lote 750 : 0.5594750860333443\n","Métricas en el lote 750 : Exactitud: 0.8575833439826965 \n","Pérdida en el lote 1125 : 0.5358647747238477\n","Métricas en el lote 1125 : Exactitud: 0.8600000143051147 \n","Pérdida en el lote 1500 : 0.5420744380156199\n","Métricas en el lote 1500 : Exactitud: 0.8611666560173035 \n","Pérdida en el lote 1875 : 0.5363586193323135\n","Métricas en el lote 1875 : Exactitud: 0.8586666584014893 \n","Pérdida entrenamiento: 0.5290089845657349, validación 0.5974875092506409\n","Métricas en entrenamiento : Exactitud: 0.8540499806404114 , validación Exactitud: 0.8314999938011169  \n","época 4:\n","Pérdida en el lote 375 : 0.5269267071485519\n","Métricas en el lote 375 : Exactitud: 0.8645833134651184 \n","Pérdida en el lote 750 : 0.521505091826121\n","Métricas en el lote 750 : Exactitud: 0.8707500100135803 \n","Pérdida en el lote 1125 : 0.5333796345988909\n","Métricas en el lote 1125 : Exactitud: 0.8669166564941406 \n","Pérdida en el lote 1500 : 0.5160661622881889\n","Métricas en el lote 1500 : Exactitud: 0.8658333420753479 \n","Pérdida en el lote 1875 : 0.35668157903353376\n","Métricas en el lote 1875 : Exactitud: 0.8784999847412109 \n","Pérdida entrenamiento: 0.29459017515182495, validación 0.36885544657707214\n","Métricas en entrenamiento : Exactitud: 0.8928499817848206 , validación Exactitud: 0.8707000017166138  \n","época 5:\n","Pérdida en el lote 375 : 0.30632357823848727\n","Métricas en el lote 375 : Exactitud: 0.8847500085830688 \n","Pérdida en el lote 750 : 0.29931098292271296\n","Métricas en el lote 750 : Exactitud: 0.8913333415985107 \n","Pérdida en el lote 1125 : 0.29948105547825493\n","Métricas en el lote 1125 : Exactitud: 0.8914999961853027 \n","Pérdida en el lote 1500 : 0.30450064794222514\n","Métricas en el lote 1500 : Exactitud: 0.8899166584014893 \n","Pérdida en el lote 1875 : 0.2866628130276998\n","Métricas en el lote 1875 : Exactitud: 0.8930833339691162 \n","Pérdida entrenamiento: 0.2645621597766876, validación 0.3566572666168213\n","Métricas en entrenamiento : Exactitud: 0.9034000039100647 , validación Exactitud: 0.8748000264167786  \n"]}]},{"cell_type":"markdown","source":["El modelo ajustado cuenta con una exactitud del 90.34% para el conjunto de entrenamiento y 87.48% en el de validación lo cual es bueno teniendo en cuenta que no se usa una red convolucional."],"metadata":{"id":"gDbwgcVS21b0"}}]}