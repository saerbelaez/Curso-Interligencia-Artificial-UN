{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Analisis Mnist Pytorch Lightning.ipynb","provenance":[{"file_id":"1rVrityAhY8YsFrWl9P8bIfFSWAByj4-a","timestamp":1654814301671}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["#An치lisis Fashion MNIST usando Pytorch Lightning\n","\n","En este cuaderno se transcribe el c칩digo propuesto para una red neuronal que permita clasificar prendas de vestir empleando la base de datos Fashion Mnist. Para el an치lisis se va a usar Pytorch Lightning"],"metadata":{"id":"rKUdQ6mKnyZi"}},{"cell_type":"code","source":["!pip install pytorch_lightning\n","import pytorch_lightning as pl\n","from pytorch_lightning import LightningModule\n","from torch.autograd import Variable\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torchvision.transforms import ToTensor\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","from torchmetrics import Accuracy\n","from datetime import datetime\n","from torch.nn.functional import softmax"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IreAEOMhoJlv","executionInfo":{"status":"ok","timestamp":1654817960012,"user_tz":300,"elapsed":9164,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}},"outputId":"3f4ac44a-1229-4bdc-a281-a1f37dad21cd"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (1.6.4)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n","Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.9.1)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.6)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.64.0)\n","Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.2.0)\n","Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n","Requirement already satisfied: protobuf<=3.20.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.17.3)\n","Requirement already satisfied: pyDeprecate>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.2)\n","Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.5.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1->pytorch_lightning) (1.15.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.46.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (57.4.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.7)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2022.5.18.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.7.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n"]}]},{"cell_type":"markdown","source":["Para la especificaci칩n del modelo se usa el modulo de lightning y se define la red neuronal que se va a ajustar."],"metadata":{"id":"b6DaVqtHyo3W"}},{"cell_type":"code","source":["class NeuralNetwork(pl.LightningModule):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","            nn.ReLU()\n","        )\n","        \n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","model = NeuralNetwork()\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qS4Ur99VsK2X","executionInfo":{"status":"ok","timestamp":1654817960014,"user_tz":300,"elapsed":10,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}},"outputId":"f8775f09-25a4-4006-834f-86ff9fa6e595"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["NeuralNetwork(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=10, bias=True)\n","    (5): ReLU()\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["A continuaci칩n se define una para ejecutar el proceso de entrenamiento"],"metadata":{"id":"6u4MoZQQyxcE"}},{"cell_type":"code","source":["class Trainer:\n","    def __init__(self, model, loss_fn, optimizer, metrics=None,\n","                 metric_names=None,\n","                 writer=None, path_to_save='',\n","                 learning_rate = 1e-3,\n","                 batch_size = 64,\n","                 epochs = 5, n_report= 1000):\n","        self.model = model\n","        self.loss_fn = loss_fn\n","        self.optimizer = optimizer\n","        self.metrics_train = metrics\n","        self.metrics_valid = self.metrics_train.copy()\n","        self.metric_names = metric_names\n","\n","        self.writer = writer\n","        \n","        self.learning_rate = learning_rate\n","        self.batch_size = batch_size\n","        self.epochs = epochs\n","        self.n_report = n_report\n","        \n","        self.path_to_save = path_to_save\n","\n","        self.best_model = None\n","        \n","        self.training_loader = None\n","\n","        self.validation_loader = None\n","     \n","    def set_model(self, model):\n","        self.model = model\n","    \n","    def set_loss(self, loss):\n","        self.loss = loss\n","        \n","    def set_optimizer(self, optimizer):\n","        self.optimizer = optimizer\n","        \n","    def set_writer(self, writer):\n","        self.writer =  writer\n","\n","    def get_model(self):\n","        return self.model\n","    \n","    \n","    def set_hiperparameters(self,\n","                 learning_rate = 1e-3,\n","                 batch_size = 64,\n","                 epochs = 5):\n","        self.learning_rate = learning_rate\n","        self.batch_size = batch_size\n","        self.epochs = epochs        \n","    \n","    def _train_one_epoch_(self, epoch_index):\n","        running_loss = 0.\n","        last_loss = 0.\n","\n","        for i, data in enumerate(self.training_loader):\n","\n","            inputs, labels = data\n","\n","            self.optimizer.zero_grad()\n","\n","            outputs = self.model(inputs)\n","            predicts = softmax(outputs, dim=-1)\n","\n","            loss = self.loss_fn(outputs, labels)\n","            loss.backward()\n","\n","            self.optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","            running_metrics = self._metric_step_(predicts, labels, metric_compute=False, \n","                                          validation=False)\n","            \n","            if i % self.n_report == (self.n_report-1):\n","\n","                last_loss = running_loss / self.n_report\n","                running_loss = 0.\n","\n","                last_metrics = self._metric_step_(None, None, metric_compute=True, \n","                                          validation=False)\n","                \n","                print('P칠rdida en el lote {} : {}'.format(i + 1, last_loss))\n","                \n","                print_m = ''\n","                for j in range(len(metrics)):\n","                    print_m += self.metric_names[j] + ': ' + str(last_metrics[j]) + ' '\n","                print('M칠tricas en el lote {} : {}'.format(i + 1, print_m))\n","                \n","                if self.writer is not None:\n","                    tb_x = epoch_index * len(training_loader) + i + 1\n","\n","                    self.writer.add_scalar('P칠rdida/Entrenamiento', last_loss, tb_x)\n","\n","                    for i in range(len(last_metric)):\n","                        self.writer.add_scalar(self.metric.names[i] + '/Entrenamiento', \n","                                               last_metrics[i], tb_x)\n","                        \n","                \n","                \n","    def _validation_step_(self, validation=True):\n","\n","        if validation:\n","            data_loader = self.validation_loader\n","        else:\n","            data_loader = self.training_loader\n","        \n","        running_vloss = 0.0   \n","        for i, vdata in enumerate(data_loader):\n","            vinputs, vlabels = vdata\n","            voutputs = self.model(vinputs)\n","            vpredicts = softmax(voutputs,dim=-1)\n","            vloss = self.loss_fn(voutputs, vlabels)\n","            \n","            running_vloss += vloss\n","            _  = self._metric_step_(vpredicts, vlabels, \n","                            metric_compute=False, validation= validation)\n","\n","        avg_vloss = running_vloss / (i + 1)\n","        v_metrics =   self._metric_step_(None, None, metric_compute=True, \n","                                          validation= validation)\n","        \n","        return avg_vloss, v_metrics\n","        \n","    def _metric_step_(self, predicts, labels, metric_compute=False, validation=False):\n","\n","        if validation:\n","            metrics = self.metrics_valid\n","        else:\n","            metrics = self.metrics_train\n","        \n","        if predicts is not None and labels is not None:\n","            for i, metric in enumerate(metrics):\n","                metrics[i].update(predicts, labels)\n","        \n","        if metric_compute:\n","            values = [metric.compute().item() for metric in metrics]\n","            for metric in metrics:\n","                metric.reset() \n","        else:\n","            values = [metric(predicts, labels).item() for metric in metrics]\n","    \n","        return values\n","      \n","    \n","    def _train_loop_(self):\n","\n","        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n","        epoch_number = 0\n","\n","\n","        best_vloss = 1_000_000.\n","        \n","         \n","\n","        for epoch in range(self.epochs):\n","            print('칠poca {}:'.format(epoch_number + 1))\n","            \n","\n","            model.train(True)\n","\n","            self._train_one_epoch_(epoch_number)\n","\n","\n","            self.model.train(False)\n","            \n","            e_loss, e_metrics = self._validation_step_(validation=False)\n","            v_loss, v_metrics = self._validation_step_(validation=True)\n","            \n","            print('P칠rdida entrenamiento: {}, validaci칩n {}'.format(e_loss, v_loss))\n","            \n","            print_m_e = ''\n","            for i in range(len(e_metrics)):\n","                print_m_e += self.metric_names[i] + ': ' + str(e_metrics[i]) + ' '\n","            print_m_v = ''\n","            for i in range(len(v_metrics)):\n","                print_m_v += self.metric_names[i] + ': ' + str(v_metrics[i]) + ' '     \n","            print('M칠tricas en entrenamiento : {}, validaci칩n {} '.format(print_m_e, print_m_v))\n","\n","\n","            if self.writer is not None:\n","                self.writer.add_scalars('P칠rdida entrenamiento v.s. P칠rdida validaci칩n',\n","                                { 'Entrenamiento' : e_loss, 'Validaci칩n' : e_vloss },\n","                                epoch_number + 1)\n","                \n","                for i in range(len(e_metrics)):  \n","                    self.writer.add_scalars(self.metric.names[i] + 'entrenamiento v.s. validaci칩n',\n","                                { 'Entrenamiento' : e_metrics[i], 'Validaci칩n' : v_metrics[i] },\n","                                epoch_number + 1)\n","                  \n","                self.writer.flush()\n","\n","            if  v_loss < best_vloss:\n","                best_vloss = v_loss\n","                model_path = self.path_to_save + 'model_{}_{}'.format(timestamp, epoch_number)\n","                torch.save(model.state_dict(), model_path)\n","                self.path_best_model = model_path\n","\n","            epoch_number += 1 \n","\n","       \n","                    \n","            \n","    def fit(self, train_data, val_data, epochs=None, writer=None, best_loss=True):\n","        if writer is not None:\n","            self.writer = writer\n","        if epochs is not None:\n","            self.epochs = epochs\n","\n","        self.training_loader = train_data\n","\n","        self.validation_loader = val_data\n","        \n","\n","        self._train_loop_()\n","\n","        if best_loss:\n","            self.model.load_state_dict(torch.load(self.path_best_model))"],"metadata":{"id":"ZqNPIR15vene","executionInfo":{"status":"ok","timestamp":1654817960733,"user_tz":300,"elapsed":725,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Adicional se define una clase para generar el conjunto de entrenamiento y validaci칩n"],"metadata":{"id":"vUY0ZXJmy8z0"}},{"cell_type":"code","source":["class Data():\n","    def __init__(self, dataset=None, batch_size=64, shuffle=True):\n","        self.dataset = dataset\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self._data = DataLoader(dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n","    \n","    # getter\n","    def get_data(self):\n","        return self._data\n","    \n","    # setter\n","    def set_data(self, dataset):\n","        self._dataset = dataset\n","        self._data = DataLoader(self._dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n","    \n","    # crea la propiedad data\n","    data = property(get_data, set_data)\n","    \n","    def __len__(self):\n","        return len(self._data)\n","    "],"metadata":{"id":"mt7_Icfkud6v","executionInfo":{"status":"ok","timestamp":1654817960734,"user_tz":300,"elapsed":7,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Se generan los conjuntos de entramiento y prueba"],"metadata":{"id":"KYaCN6b8zE2l"}},{"cell_type":"code","source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))])\n","\n","train_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=transform\n",")\n","\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=transform\n",")"],"metadata":{"id":"JClX6ndxzmje","executionInfo":{"status":"ok","timestamp":1654817961013,"user_tz":300,"elapsed":284,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["train = Data(train_data, batch_size=32)\n","validation = Data(test_data, batch_size=32, shuffle=False)"],"metadata":{"id":"ZUJDqf2Qt2Tn","executionInfo":{"status":"ok","timestamp":1654817961014,"user_tz":300,"elapsed":6,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Ahora se definen los optimizadores y las funciones de p칠rdida. Debido a que la red que se est치 entrenando es realtivamente compleja, se guarda el checkpoint para usarlo con otros datos."],"metadata":{"id":"pkl61Tsrzt59"}},{"cell_type":"code","source":["model = NeuralNetwork()\n","\n","# Optimizador\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","# Funci칩n de p칠rdida\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","# initializa m칠trica\n","# se espera una lista de m칠tricas\n","metrics = [Accuracy()] # accuracy\n","# pasar nombre en espa침ol de la m칠trica\n","# TODO hacer esto con una clase traductora\n","metric_names = ['Exactitud']\n","# path para almacenar los pesos de los mejores modelos\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","path_to_save = '/content/gdrive/MyDrive/Colab Notebooks'\n","\n","# Trainer\n","trainer = Trainer(model=model, loss_fn=loss_fn,  \n","                  optimizer=optimizer, metrics=metrics, \n","                  metric_names = metric_names,\n","                  n_report=375, path_to_save= path_to_save )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKMhJeUtus_G","executionInfo":{"status":"ok","timestamp":1654817962369,"user_tz":300,"elapsed":1360,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}},"outputId":"90b4633a-2231-4390-a379-86a05009ad04"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Se ajusta el modelo de entramiento a los datos de validaci칩n para determinar su precisi칩n"],"metadata":{"id":"MaqW_4RFz7L8"}},{"cell_type":"code","source":["trainer.fit(train.data, validation.data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3kQZ54FKwSV1","executionInfo":{"status":"ok","timestamp":1654818291089,"user_tz":300,"elapsed":328725,"user":{"displayName":"Sebastian Arbelaez Quintero","userId":"14051500047426925086"}},"outputId":"2816a59b-8ff1-448c-c69a-9902a8bedacd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["칠poca 1:\n","P칠rdida en el lote 375 : 1.4949666884740194\n","M칠tricas en el lote 375 : Exactitud: 0.4857499897480011 \n","P칠rdida en el lote 750 : 1.1020420747598012\n","M칠tricas en el lote 750 : Exactitud: 0.6317499876022339 \n","P칠rdida en el lote 1125 : 0.808643186767896\n","M칠tricas en el lote 1125 : Exactitud: 0.746916651725769 \n","P칠rdida en el lote 1500 : 0.6376968868970871\n","M칠tricas en el lote 1500 : Exactitud: 0.8212500214576721 \n","P칠rdida en el lote 1875 : 0.6097861173550287\n","M칠tricas en el lote 1875 : Exactitud: 0.8303333520889282 \n","P칠rdida entrenamiento: 0.5756624341011047, validaci칩n 0.6217970252037048\n","M칠tricas en entrenamiento : Exactitud: 0.8401833176612854 , validaci칩n Exactitud: 0.822700023651123  \n","칠poca 2:\n","P칠rdida en el lote 375 : 0.6160221873521805\n","M칠tricas en el lote 375 : Exactitud: 0.8335833549499512 \n","P칠rdida en el lote 750 : 0.5837854881683986\n","M칠tricas en el lote 750 : Exactitud: 0.8454166650772095 \n","P칠rdida en el lote 1125 : 0.5674816248615583\n","M칠tricas en el lote 1125 : Exactitud: 0.8524166941642761 \n","P칠rdida en el lote 1500 : 0.5842154634793599\n","M칠tricas en el lote 1500 : Exactitud: 0.8472499847412109 \n","P칠rdida en el lote 1875 : 0.5610184919436773\n","M칠tricas en el lote 1875 : Exactitud: 0.8482499718666077 \n","P칠rdida entrenamiento: 0.5710232257843018, validaci칩n 0.6205582618713379\n","M칠tricas en entrenamiento : Exactitud: 0.8400333523750305 , validaci칩n Exactitud: 0.8224999904632568  \n","칠poca 3:\n","P칠rdida en el lote 375 : 0.5502252042889595\n","M칠tricas en el lote 375 : Exactitud: 0.8514166474342346 \n","P칠rdida en el lote 750 : 0.5594750860333443\n","M칠tricas en el lote 750 : Exactitud: 0.8575833439826965 \n","P칠rdida en el lote 1125 : 0.5358647747238477\n","M칠tricas en el lote 1125 : Exactitud: 0.8600000143051147 \n","P칠rdida en el lote 1500 : 0.5420744380156199\n","M칠tricas en el lote 1500 : Exactitud: 0.8611666560173035 \n","P칠rdida en el lote 1875 : 0.5363586193323135\n","M칠tricas en el lote 1875 : Exactitud: 0.8586666584014893 \n","P칠rdida entrenamiento: 0.5290089845657349, validaci칩n 0.5974875092506409\n","M칠tricas en entrenamiento : Exactitud: 0.8540499806404114 , validaci칩n Exactitud: 0.8314999938011169  \n","칠poca 4:\n","P칠rdida en el lote 375 : 0.5269267071485519\n","M칠tricas en el lote 375 : Exactitud: 0.8645833134651184 \n","P칠rdida en el lote 750 : 0.521505091826121\n","M칠tricas en el lote 750 : Exactitud: 0.8707500100135803 \n","P칠rdida en el lote 1125 : 0.5333796345988909\n","M칠tricas en el lote 1125 : Exactitud: 0.8669166564941406 \n","P칠rdida en el lote 1500 : 0.5160661622881889\n","M칠tricas en el lote 1500 : Exactitud: 0.8658333420753479 \n","P칠rdida en el lote 1875 : 0.35668157903353376\n","M칠tricas en el lote 1875 : Exactitud: 0.8784999847412109 \n","P칠rdida entrenamiento: 0.29459017515182495, validaci칩n 0.36885544657707214\n","M칠tricas en entrenamiento : Exactitud: 0.8928499817848206 , validaci칩n Exactitud: 0.8707000017166138  \n","칠poca 5:\n","P칠rdida en el lote 375 : 0.30632357823848727\n","M칠tricas en el lote 375 : Exactitud: 0.8847500085830688 \n","P칠rdida en el lote 750 : 0.29931098292271296\n","M칠tricas en el lote 750 : Exactitud: 0.8913333415985107 \n","P칠rdida en el lote 1125 : 0.29948105547825493\n","M칠tricas en el lote 1125 : Exactitud: 0.8914999961853027 \n","P칠rdida en el lote 1500 : 0.30450064794222514\n","M칠tricas en el lote 1500 : Exactitud: 0.8899166584014893 \n","P칠rdida en el lote 1875 : 0.2866628130276998\n","M칠tricas en el lote 1875 : Exactitud: 0.8930833339691162 \n","P칠rdida entrenamiento: 0.2645621597766876, validaci칩n 0.3566572666168213\n","M칠tricas en entrenamiento : Exactitud: 0.9034000039100647 , validaci칩n Exactitud: 0.8748000264167786  \n"]}]},{"cell_type":"markdown","source":["El modelo ajustado cuenta con una exactitud del 90.34% para el conjunto de entrenamiento y 87.48% en el de validaci칩n lo cual es bueno teniendo en cuenta que no se usa una red convolucional."],"metadata":{"id":"gDbwgcVS21b0"}}]}